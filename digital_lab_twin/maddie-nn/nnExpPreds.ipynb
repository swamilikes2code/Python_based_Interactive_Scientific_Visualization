{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports/Intro\n",
    "This file's going to take the models created in neuralnet.ipynb and attempt to generate a set of 'experimental data' from their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "import pathlib as path\n",
    "import copy\n",
    "import random\n",
    "# Check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Model loadin\n",
    "Much like previous notebook, we need access to the data and models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenda\\AppData\\Local\\Temp\\ipykernel_4420\\3039068683.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(index=19999, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv('STEMVisualsSynthData.csv', header=0)\n",
    "#remove unneeded column\n",
    "rawData.drop('Index_within_Experiment', axis = 1, inplace = True)\n",
    "#X is inputs--the three Concentrations, F_in, I0 (light intensity), and c_N_in (6)\n",
    "X = rawData[['Time', 'C_X', 'C_N', 'C_L', 'F_in', 'C_N_in', 'I0']]\n",
    "Y = X.copy(deep=True)\n",
    "#drop unnecessary rows in Y\n",
    "Y.drop('F_in', axis = 1, inplace = True)\n",
    "Y.drop('C_N_in', axis = 1, inplace = True)\n",
    "Y.drop('I0', axis = 1, inplace = True)\n",
    "Y.drop('Time', axis = 1, inplace = True)\n",
    "#Y vals should be X concentrations one timestep ahead, so remove the first index\n",
    "Y.drop(index=0, inplace=True)\n",
    "#To keep the two consistent, remove the last index of X\n",
    "X.drop(index=19999, inplace=True)\n",
    "#separate the times out into their own little thing for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 50),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(50, 25),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(25, 12),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(12, 3)\n",
    ")\n",
    "#loss/optimizer\n",
    "loss_fn = nn.MSELoss() #Mean Squared Error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "model.load_state_dict(torch.load('models/model.pt'))\n",
    "#scalers\n",
    "mmscalerX = joblib.load('models/mmscalerX.pkl')\n",
    "mmscalerY = joblib.load('models/mmscalerY.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Isolation\n",
    "- there are 100 experiments with 200 datapoints each making up our 20k datapoint set\n",
    "- randomly pick a number 0-99, then select the 200 matching datapoints to create a subset representing 1 experiment\n",
    "- can set random seed if you want same run every time at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42) #comment out if you want different random numbers\n",
    "#randomly select an experiment\n",
    "expNum = random.randint(0, 99)\n",
    "indexStart = expNum*200\n",
    "indexEnd = indexStart + 200\n",
    "#select the experiment\n",
    "X_exp = X.iloc[indexStart:indexEnd]\n",
    "Y_exp = Y.iloc[indexStart:indexEnd]\n",
    "#to match model shape, pop time column\n",
    "XTimes = X_exp.pop('Time')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Model Output\n",
    "- the model needs the initial conditions of the experiment; our outputs will be the 3 concentrations\n",
    "- lets create a copy of the x dataframe's first row to be our initial input\n",
    "- we'll generate our model's experiment one row at a time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_X</th>\n",
       "      <th>C_N</th>\n",
       "      <th>C_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.199901</td>\n",
       "      <td>1.966507</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C_X       C_N       C_L\n",
       "0  1.199901  1.966507  0.000435"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XIn = X_exp.iloc[0]\n",
    "#scale the input\n",
    "XIn = mmscalerX.transform([XIn])\n",
    "XIn = torch.tensor(XIn, dtype=torch.float32)\n",
    "# 1. Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# 2. Setup the inference mode context manager\n",
    "with torch.inference_mode():\n",
    "  # 3. Make sure the calculations are done with the model and data on the same device\n",
    "  y_preds = model(XIn)\n",
    "y_preds \n",
    "#scale the output back up\n",
    "y_preds = y_preds.detach().numpy()\n",
    "y_preds = mmscalerY.inverse_transform(y_preds)\n",
    "y_preds = pd.DataFrame(y_preds, columns=['C_X', 'C_N', 'C_L'])\n",
    "y_preds "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
