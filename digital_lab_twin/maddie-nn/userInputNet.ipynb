{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro/Imports\n",
    "This is going to be a more granular, customizable neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "import pathlib as path\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Read-in\n",
    "unchanged from neuralnet.ipynb; this is non-negotiable. \n",
    "For any of the user changes to work, I need to know the shape of the data; so this split will be universal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenda\\AppData\\Local\\Temp\\ipykernel_27940\\3039068683.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(index=19999, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv('STEMVisualsSynthData.csv', header=0)\n",
    "#remove unneeded column\n",
    "rawData.drop('Index_within_Experiment', axis = 1, inplace = True)\n",
    "#X is inputs--the three Concentrations, F_in, I0 (light intensity), and c_N_in (6)\n",
    "X = rawData[['Time', 'C_X', 'C_N', 'C_L', 'F_in', 'C_N_in', 'I0']]\n",
    "Y = X.copy(deep=True)\n",
    "#drop unnecessary rows in Y\n",
    "Y.drop('F_in', axis = 1, inplace = True)\n",
    "Y.drop('C_N_in', axis = 1, inplace = True)\n",
    "Y.drop('I0', axis = 1, inplace = True)\n",
    "Y.drop('Time', axis = 1, inplace = True)\n",
    "#Y vals should be X concentrations one timestep ahead, so remove the first index\n",
    "Y.drop(index=0, inplace=True)\n",
    "#To keep the two consistent, remove the last index of X\n",
    "X.drop(index=19999, inplace=True)\n",
    "#separate the times out into their own little thing for later use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split\n",
    "Keeping it simple stupid, there's only 1 split happening here. User chooses the percentage of data to hold out for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defaults\n",
    "train_ratio = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1 - train_ratio)\n",
    "\n",
    "#function to call whenever wanting to change the train/test split\n",
    "def trainSplit():\n",
    "    train_ratio = float(input(\"What percentage of data to holdout for testing? (default 0.2) \"))\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1 - train_ratio)\n",
    "\n",
    "#Separate Time out--we don't want this as a feature the model learns (since it's already incorporated in by how X and Y are structured!)\n",
    "#however, having the time values will be useful for plotting later\n",
    "XTrainTime = X_train.pop('Time')\n",
    "XTestTime = X_test.pop('Time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Another thing I'm going to just have to have happen backend without the user's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for both x and y, create a min max scaler\n",
    "mmscalerX = preprocessing.MinMaxScaler()\n",
    "#we'll fit and transform based on training data\n",
    "X_train_minmax = mmscalerX.fit_transform(X_train)\n",
    "#transform testing data based on training data\n",
    "X_test_minmax = mmscalerX.transform(X_test)\n",
    "#same process as above for Y\n",
    "mmscalerY = preprocessing.MinMaxScaler()\n",
    "Y_train_minmax = mmscalerY.fit_transform(Y_train)\n",
    "Y_test_minmax = mmscalerY.transform(Y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put our data into tensors\n",
    "X_train = torch.tensor(X_train_minmax, dtype=torch.float32)\n",
    "y_train = torch.tensor(Y_train_minmax, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_minmax, dtype=torch.float32)\n",
    "y_test = torch.tensor(Y_test_minmax, dtype=torch.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
