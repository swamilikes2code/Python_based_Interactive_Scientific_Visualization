{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenda\\AppData\\Local\\Temp\\ipykernel_27240\\860850889.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(index=19999, inplace=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m X_train_tensor, X_val_tensor, X_test_tensor, Y_train_tensor, Y_val_tensor, Y_test_tensor \u001b[39m=\u001b[39m mnn\u001b[39m.\u001b[39mtensors(X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled)\n\u001b[0;32m     53\u001b[0m \u001b[39m#create the model\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m model, lossFunction, optimizer \u001b[39m=\u001b[39m mnn\u001b[39m.\u001b[39;49mmodelCreator(initNeuronNum, loss, optimizer, learnRate)\n\u001b[0;32m     55\u001b[0m \u001b[39m#train the model\u001b[39;00m\n\u001b[0;32m     56\u001b[0m model, trainLoss, valLoss \u001b[39m=\u001b[39m mnn\u001b[39m.\u001b[39mtrainModel(model, lossFunction, optimizer, epochs, batchSize, X_train_tensor, X_val_tensor, Y_train_tensor, Y_val_tensor)\n",
      "File \u001b[1;32mc:\\Users\\kenda\\Documents\\GitHub\\Python_based_Interactive_Scientific_Visualization\\digital_lab_twin\\maddie-nn\\modularNN.py:57\u001b[0m, in \u001b[0;36mmodelCreator\u001b[1;34m(initNeuronNum, loss, optimizer, learnRate)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodelCreator\u001b[39m(initNeuronNum, loss, optimizer, learnRate):\n\u001b[0;32m     53\u001b[0m     \u001b[39m#create the model\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     model \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     55\u001b[0m         nn\u001b[39m.\u001b[39mLinear(\u001b[39m6\u001b[39m, initNeuronNum), \n\u001b[0;32m     56\u001b[0m         nn\u001b[39m.\u001b[39mLeakyReLU(), \n\u001b[1;32m---> 57\u001b[0m         nn\u001b[39m.\u001b[39;49mLinear(initNeuronNum, (initNeuronNum\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m)),\n\u001b[0;32m     58\u001b[0m         nn\u001b[39m.\u001b[39mLeakyReLU(),\n\u001b[0;32m     59\u001b[0m         nn\u001b[39m.\u001b[39mLinear((initNeuronNum\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m), \u001b[39m3\u001b[39m))\n\u001b[0;32m     60\u001b[0m     \u001b[39m#define the loss function\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m loss \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty((out_features, in_features), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs))\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "import pathlib as path\n",
    "import copy\n",
    "import modularNN as mnn\n",
    "\n",
    "### Static\n",
    "rawData = pd.read_csv('STEMVisualsSynthData.csv', header=0)\n",
    "#remove unneeded column\n",
    "rawData.drop('Index_within_Experiment', axis = 1, inplace = True)\n",
    "#X is inputs--the three Concentrations, F_in, I0 (light intensity), and c_N_in (6)\n",
    "X = rawData[['Time', 'C_X', 'C_N', 'C_L', 'F_in', 'C_N_in', 'I0']]\n",
    "Y = X.copy(deep=True)\n",
    "#drop unnecessary rows in Y\n",
    "Y.drop('F_in', axis = 1, inplace = True)\n",
    "Y.drop('C_N_in', axis = 1, inplace = True)\n",
    "Y.drop('I0', axis = 1, inplace = True)\n",
    "Y.drop('Time', axis = 1, inplace = True)\n",
    "#Y vals should be X concentrations one timestep ahead, so remove the first index\n",
    "Y.drop(index=0, inplace=True)\n",
    "#To keep the two consistent, remove the last index of X\n",
    "X.drop(index=19999, inplace=True)\n",
    "\n",
    "#user defined parameters: current values can serve as a default\n",
    "#splits - expects 3 floats that add to 1\n",
    "trainSplit = 0.6\n",
    "valSplit = 0.1\n",
    "testSplit = 0.3\n",
    "#model params\n",
    "initNeuronNum = 50 #number of neurons in the first layer, 0 < int < 100\n",
    "loss = 0 #0 = MSE, 1 = MAE\n",
    "optimizer = 0 #0 = Adam, 1 = SGD\n",
    "learnRate = 0.001 #0 < float < 0.1\n",
    "#training params\n",
    "epochs = 100 #0 < int < 1000\n",
    "batchSize = 100 #0 < int < 1000\n",
    "\n",
    "#split the data\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test, XTrainTime, XValTime, XTestTime = mnn.dataSplitter(X, Y, trainSplit, valSplit, testSplit)\n",
    "#scale the data\n",
    "stScalerX, stScalerY, X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled= mnn.scaleData(X_train, X_val, X_test, Y_train, Y_val, Y_test)\n",
    "#tensorize the data\n",
    "X_train_tensor, X_val_tensor, X_test_tensor, Y_train_tensor, Y_val_tensor, Y_test_tensor = mnn.tensors(X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled)\n",
    "#create the model\n",
    "model, lossFunction, optimizer = mnn.modelCreator(initNeuronNum, loss, optimizer, learnRate)\n",
    "#train the model\n",
    "model, trainLoss, valLoss = mnn.trainModel(model, lossFunction, optimizer, epochs, batchSize, X_train_tensor, X_val_tensor, Y_train_tensor, Y_val_tensor)\n",
    "#test the model\n",
    "testLoss = mnn.testModel(model, lossFunction, X_test_tensor, Y_test_tensor)\n",
    "#plot the results\n",
    "mnn.plotter(trainLoss, valLoss)\n",
    "#mnn.plotPredictions(X_test_tensor, Y_test_tensor, model, stScalerX, stScalerY)\n",
    "#plt.show()\n",
    "#save the model\n",
    "mnn.saveModel(model, stScalerX, stScalerY)\n",
    "#TODO: save the model, scalers, and parameters to a file\n",
    "#TODO: move this to a ipynb file for easy running/visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
