{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "import pathlib as path\n",
    "import copy\n",
    "import modularNN as mnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenda\\AppData\\Local\\Temp\\ipykernel_24676\\4255612499.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(index=19999, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "### Static\n",
    "rawData = pd.read_csv('STEMVisualsSynthData.csv', header=0)\n",
    "#remove unneeded column\n",
    "rawData.drop('Index_within_Experiment', axis = 1, inplace = True)\n",
    "#X is inputs--the three Concentrations, F_in, I0 (light intensity), and c_N_in (6)\n",
    "X = rawData[['Time', 'C_X', 'C_N', 'C_L', 'F_in', 'C_N_in', 'I0']]\n",
    "Y = X.copy(deep=True)\n",
    "#drop unnecessary rows in Y\n",
    "Y.drop('F_in', axis = 1, inplace = True)\n",
    "Y.drop('C_N_in', axis = 1, inplace = True)\n",
    "Y.drop('I0', axis = 1, inplace = True)\n",
    "Y.drop('Time', axis = 1, inplace = True)\n",
    "#Y vals should be X concentrations one timestep ahead, so remove the first index\n",
    "Y.drop(index=0, inplace=True)\n",
    "#To keep the two consistent, remove the last index of X\n",
    "X.drop(index=19999, inplace=True)\n",
    "\n",
    "#user defined parameters: current values can serve as a default\n",
    "#splits - expects 3 floats that add to 1\n",
    "trainSplit = 0.6\n",
    "valSplit = 0.2\n",
    "testSplit = 0.2\n",
    "#model params\n",
    "initNeuronNum = 18 #number of neurons in the first layer, 7 < int < 100\n",
    "loss = 1 #0 = MSE, 1 = MAE\n",
    "optimizer = 0 #0 = Adam, 1 = SGD\n",
    "learnRate = 0.001 #0 < float < 0.1\n",
    "#training params\n",
    "epochs = 100 #0 < int < 1000\n",
    "batchSize = 25 #0 < int < 1000\n",
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the all-in-one function\n",
    "mnn.trainAndSaveModel(X, Y, trainSplit, valSplit, testSplit, initNeuronNum, loss, optimizer, learnRate, epochs, batchSize, device)\n",
    "#TODO: access the loss CSVs and plot them as a loss graph (train loss and val loss versus epochs; 0th column is epochs, 1st column is train loss, 2nd column is val loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m \u001b[39m#train the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model, trainLoss, valLoss \u001b[39m=\u001b[39m mnn\u001b[39m.\u001b[39;49mtrainModel(model, lossFunction, optimizer, epochs, batchSize, X_train_tensor, X_val_tensor, Y_train_tensor, Y_val_tensor)\n\u001b[0;32m     21\u001b[0m \u001b[39m#test the model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m#testLoss = mnn.testModel(model, lossFunction, X_test_tensor, Y_test_tensor)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m#plot the results\u001b[39;00m\n\u001b[0;32m     24\u001b[0m mnn\u001b[39m.\u001b[39mplotter(trainLoss, valLoss)\n",
      "File \u001b[1;32mc:\\Users\\kenda\\Documents\\GitHub\\Python_based_Interactive_Scientific_Visualization\\digital_lab_twin\\maddie-nn\\modularNN.py:92\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(model, lossFunction, optimizer, epochs, batchSize, X_train_tensor, X_val_tensor, Y_train_tensor, Y_val_tensor)\u001b[0m\n\u001b[0;32m     90\u001b[0m y_batch \u001b[39m=\u001b[39m Y_train_tensor[start:start\u001b[39m+\u001b[39mbatchSize]\n\u001b[0;32m     91\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m y_pred \u001b[39m=\u001b[39m model(X_batch)\n\u001b[0;32m     93\u001b[0m loss \u001b[39m=\u001b[39m lossFunction(y_pred, y_batch)\n\u001b[0;32m     94\u001b[0m \u001b[39m# backward pass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test, XTrainTime, XValTime, XTestTime = mnn.dataSplitter(X, Y, trainSplit, valSplit, testSplit)\n",
    "#scale the data\n",
    "stScalerX, stScalerY, X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled= mnn.scaleData(X_train, X_val, X_test, Y_train, Y_val, Y_test)\n",
    "#tensorize the data\n",
    "X_train_tensor, X_val_tensor, X_test_tensor, Y_train_tensor, Y_val_tensor, Y_test_tensor = mnn.tensors(X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled)\n",
    "#if possible, move the tensors to the GPU\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "X_val_tensor = X_val_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "Y_train_tensor = Y_train_tensor.to(device)\n",
    "Y_val_tensor = Y_val_tensor.to(device)\n",
    "Y_test_tensor = Y_test_tensor.to(device)\n",
    "\n",
    "#create the model\n",
    "model, lossFunction, optimizer = mnn.modelCreator(initNeuronNum, loss, optimizer, learnRate)\n",
    "#if possible, move the model to the GPU\n",
    "model = model.to(device)\n",
    "#train the model\n",
    "model, trainLoss, valLoss = mnn.trainModel(model, lossFunction, optimizer, epochs, batchSize, X_train_tensor, X_val_tensor, Y_train_tensor, Y_val_tensor)\n",
    "#test the model\n",
    "#testLoss = mnn.testModel(model, lossFunction, X_test_tensor, Y_test_tensor)\n",
    "#plot the results\n",
    "mnn.plotter(trainLoss, valLoss)\n",
    "with torch.inference_mode():\n",
    "  # 3. Make sure the calculations are done with the model and data on the same device\n",
    "  y_preds = model(X_test_tensor)\n",
    "mnn.plot_predictions(train_data=XTrainTime, \n",
    "                     train_labels=Y_train_tensor[:, 1], \n",
    "                     test_data=XTestTime, \n",
    "                     test_labels=Y_test_tensor[:, 1], \n",
    "                     predictions= torch.Tensor.cpu(y_preds[:, 1]))\n",
    "#save the model\n",
    "mnn.saveModel(model, stScalerX, stScalerY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.0001\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0011\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0021\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0031\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0041\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0051\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0061\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0071\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0081\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Learning Rate:  0.0091\n",
      "Epochs:  50\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  75\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  100\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n",
      "Epochs:  125\n",
      "Batch Size:  25\n",
      "Batch Size:  50\n",
      "Batch Size:  75\n",
      "Batch Size:  100\n",
      "Batch Size:  125\n",
      "Batch Size:  150\n",
      "Batch Size:  175\n"
     ]
    }
   ],
   "source": [
    "#for loop to find best model\n",
    "#create array to hold best model parameters\n",
    "bestModel = []\n",
    "#hold best loss\n",
    "bestLoss = np.inf #start at infinity\n",
    "#neuronnum, loss, opt are static\n",
    "initNeuronNum = 18\n",
    "loss = 1\n",
    "opt = 0\n",
    "#learnRate will be between 0.0001 and 0.01, step size 0.001\n",
    "for lr in range(1, 100, 10):\n",
    "        learnRate = lr/10000\n",
    "        #print learn rate\n",
    "        print(\"Learning Rate: \", learnRate)\n",
    "        #epochs will be between 25 and 200, step size 25\n",
    "        for epoch in range(50, 150, 25):\n",
    "            epochs = epoch\n",
    "            #print epoch\n",
    "            print(\"Epochs: \", epochs)\n",
    "            #batchSize will be between 25 and 200, step size 25\n",
    "            for batch in range(25, 200, 25):\n",
    "                batchSize = batch\n",
    "                #print batch size\n",
    "                print(\"Batch Size: \", batchSize)\n",
    "                #splits will be .6 train, .2 val, .2 test\n",
    "                trainSplit = 0.6\n",
    "                valSplit = 0.2\n",
    "                testSplit = 0.2\n",
    "                #split the data\n",
    "                X_train, X_val, X_test, Y_train, Y_val, Y_test, XTrainTime, XValTime, XTestTime = mnn.dataSplitter(X, Y, trainSplit, valSplit, testSplit)\n",
    "                #scale the data\n",
    "                stScalerX, stScalerY, X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled= mnn.scaleData(X_train, X_val, X_test, Y_train, Y_val, Y_test)\n",
    "                #tensorize the data\n",
    "                X_train_tensor, X_val_tensor, X_test_tensor, Y_train_tensor, Y_val_tensor, Y_test_tensor = mnn.tensors(X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled)\n",
    "                #if possible, move the tensors to the GPU\n",
    "                X_train_tensor = X_train_tensor.to(device)\n",
    "                X_val_tensor = X_val_tensor.to(device)\n",
    "                X_test_tensor = X_test_tensor.to(device)\n",
    "                Y_train_tensor = Y_train_tensor.to(device)\n",
    "                Y_val_tensor = Y_val_tensor.to(device)\n",
    "                Y_test_tensor = Y_test_tensor.to(device)\n",
    "\n",
    "                #create the model\n",
    "                model, lossFunction, optimizer = mnn.modelCreator(initNeuronNum, loss, optimizer, learnRate)\n",
    "                #if possible, move the model to the GPU\n",
    "                model = model.to(device)\n",
    "                #train the model\n",
    "                model, trainLoss, valLoss = mnn.trainModel(model, lossFunction, optimizer, epochs, batchSize, X_train_tensor, X_val_tensor, Y_train_tensor, Y_val_tensor)\n",
    "                #if the model is better than the current best model, save it\n",
    "                if valLoss[epochs-1] < bestLoss: #if the last value in the validation loss is less than the current best loss\n",
    "                    bestLoss = valLoss[epochs-1] #set the best loss to the last value in the validation loss\n",
    "                    bestModel = [initNeuronNum, loss, optimizer, learnRate, epochs, batchSize] #set the best model parameters to the current model parameters\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 1, Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), 0.0081, 100, 25]\n"
     ]
    }
   ],
   "source": [
    "print(bestModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
